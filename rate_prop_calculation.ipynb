{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17dcddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "481aa224",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_begin = 13\n",
    "age_end = 100\n",
    "risk_groups = ['HM', 'HF', 'MSM']\n",
    "num_risk = 3\n",
    "\n",
    "all_jur = 10\n",
    "age_groups = 88\n",
    "number_of_risk_groups = 3\n",
    "number_of_compartments = 22\n",
    "dt = 1/12\n",
    "\n",
    "num_age = 88\n",
    "num_comp = number_of_compartments-2\n",
    "\n",
    "prep_efficiency = 0.99\n",
    "\n",
    "unaware_index = (1,5,9,13,17)\n",
    "aware_no_care_index = (2,6,10,14,18)\n",
    "ART_VLS_index = (3,4,7,8,11,12,15,16,19,20)\n",
    "VLS_index = (4,8,12,16,20)\n",
    "\n",
    "\n",
    "pop_growth_rate = 0\n",
    "\n",
    "gamma = np.array([[0.5,0.5,0.5,0.5,1],\n",
    "                  [0.5,0.5,0.5,0.5,1],\n",
    "                  [0.5,0.5,0.5,0.5,1]])\n",
    "\n",
    "scaling_factor_dropout = np.array([[1,1,1,1,1,1,1,1,0,0],\n",
    "                                   [1,1,1,1,1,1,1,1,0,0],\n",
    "                                   [1,1,1,1,1,1,1,1,0,0]])\n",
    "\n",
    "all_jurisdictions = [6001,6037,6059,6065,6067,6071,6073,6]\n",
    "\n",
    "num_jur = len(all_jurisdictions)\n",
    "\n",
    "cluster1 = [6001]\n",
    "cluster2 = [6037]\n",
    "cluster3 = [6059]\n",
    "cluster4 = [6065]\n",
    "cluster5 = [6067]\n",
    "cluster6 = [6071]\n",
    "cluster7 = [6073]\n",
    "cluster8 = [6]\n",
    "\n",
    "cluster1_index = np.array([0])\n",
    "cluster2_index = np.array([1])\n",
    "cluster3_index = np.array([2])\n",
    "cluster4_index = np.array([3])\n",
    "cluster5_index = np.array([4])\n",
    "cluster6_index = np.array([5])\n",
    "cluster7_index = np.array([6])\n",
    "cluster8_index = np.array([7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2a6ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.reading_files import read_new_inf_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18d6e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_infections_data = read_new_inf_input(age_begin, age_end, risk_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ba699",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixing_excel = './input_files/JURI_mixing_weightedBydistance-6-3-2021.xlsx'\n",
    "\n",
    "mixing_df_hm = pd.read_excel(mixing_excel, sheet_name='HETM_mixing')\n",
    "mixing_df_hf = pd.read_excel(mixing_excel, sheet_name='HETF_mixing')\n",
    "mixing_df_msm = pd.read_excel(mixing_excel, sheet_name='MSM_mixing')\n",
    "\n",
    "mixing_df_hm = mixing_df_hm[['FIPS', 6001,6037,6059,6065,6067,6071,6073,6]]\n",
    "mixing_df_hf = mixing_df_hf[['FIPS', 6001,6037,6059,6065,6067,6071,6073,6]]\n",
    "mixing_df_msm = mixing_df_msm[['FIPS', 6001,6037,6059,6065,6067,6071,6073,6]]\n",
    "\n",
    "mixing_hm = mixing_df_hm.loc[mixing_df_hm['FIPS'].isin(all_jurisdictions)]\n",
    "mixing_hf = mixing_df_hf.loc[mixing_df_hf['FIPS'].isin(all_jurisdictions)]\n",
    "mixing_msm = mixing_df_msm.loc[mixing_df_msm['FIPS'].isin(all_jurisdictions)]\n",
    "\n",
    "hm_array = mixing_hm.values[:,1:]\n",
    "hf_array = mixing_hf.values[:,1:]\n",
    "msm_array = mixing_msm.values[:,1:]\n",
    "\n",
    "hm_sum = np.sum(hm_array, axis=1)\n",
    "hf_sum = np.sum(hf_array, axis=1)\n",
    "msm_sum = np.sum(msm_array, axis=1)\n",
    "\n",
    "hm_array_scaled = hm_array / hm_sum[:,np.newaxis]\n",
    "hf_array_scaled = hf_array / hf_sum[:,np.newaxis]\n",
    "msm_array_scaled = msm_array / msm_sum[:,np.newaxis]\n",
    "\n",
    "mixing_matrix = np.zeros((num_risk,len(all_jurisdictions), len(all_jurisdictions)))\n",
    "\n",
    "mixing_matrix[0,:,:] = hm_array_scaled[:,:]\n",
    "mixing_matrix[1,:,:] = hf_array_scaled[:,:]\n",
    "mixing_matrix[2,:,:] = msm_array_scaled[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfc5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_infections_per_month(num_jur, data_array, new_infections_data, M_x1_y1_i, prep_risk):\n",
    "    \n",
    "    risk_mat = new_infections_data[\"sex_mixing\"].copy()[0:num_risk,0:num_risk]\n",
    "    age_mat = new_infections_data[\"age_mixing_final_mat\"].copy()\n",
    "    \n",
    "    I = data_array[:,:,:,1:21]\n",
    "    N = np.sum(data_array[:,:,:,0:21], axis=3)\n",
    "    d_x1_y1 = new_infections_data[\"num_partner_risk_casual\"].copy()+new_infections_data[\"num_partner_risk_casual_only\"].copy()\n",
    "    sus_x1_y1 = data_array[:,:,:,0]\n",
    "    mat_vector = np.repeat(age_mat[:,np.newaxis,:,:],num_risk, axis = 1) * risk_mat[:,:,np.newaxis, np.newaxis]\n",
    "    I_N_vector = I / N[:,:,:,np.newaxis]\n",
    "    I_N_mult_vector = mat_vector[np.newaxis,:,:,:,:,np.newaxis]*I_N_vector[:,np.newaxis,:,np.newaxis,:,:]\n",
    "    Q_inner_vector = np.apply_over_axes(np.sum, I_N_mult_vector, [2,4]).reshape((num_jur, num_risk,num_age,num_comp))\n",
    "    q_x_y_i_vector = d_x1_y1[np.newaxis,:,np.newaxis,np.newaxis]*dt*Q_inner_vector\n",
    "    q_mix_vector = np.zeros((num_jur,num_jur,num_risk,num_age,num_comp))\n",
    "    for risk in range(num_risk):\n",
    "        q_mix_vector[:,:,risk,:,:] = mixing_matrix[risk][:,:,np.newaxis,np.newaxis]*q_x_y_i_vector[:,risk,:,:][np.newaxis,:,:,:]\n",
    "    q_mix_sum_vector = np.sum(q_mix_vector, axis = 1)\n",
    "    M_power_vector = M_x1_y1_i[np.newaxis,:,:,:]**q_mix_sum_vector\n",
    "    M_prod_vector = 1-np.prod(M_power_vector, axis = 3) \n",
    "    \n",
    "    new_inf_per_month = sus_x1_y1*(1 - prep_risk[:,:,np.newaxis])*M_prod_vector\n",
    "    \n",
    "    return new_inf_per_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_proportions(data_array, num_jur, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index,VLS_index):\n",
    "    \n",
    "    plwh_risk = np.zeros((num_jur, number_of_risk_groups))\n",
    "    unaware_risk = np.zeros((num_jur, number_of_risk_groups))\n",
    "    aware_no_art_risk = np.zeros((num_jur, number_of_risk_groups))\n",
    "    aware_art_vls_risk = np.zeros((num_jur, number_of_risk_groups))\n",
    "    vls_risk = np.zeros((num_jur, number_of_risk_groups))\n",
    "    \n",
    "    for risk in range(number_of_risk_groups):\n",
    "        plwh_risk[:,risk] = np.apply_over_axes(np.sum, data_array[:,risk,:,1:21], [1,2]).reshape(num_jur,)\n",
    "#         print('risk')\n",
    "#         print(plwh_risk[risk])\n",
    "        unaware_risk[:,risk] = np.apply_over_axes(np.sum, data_array[:,risk,:,unaware_index], [0,2]).reshape(num_jur,)\n",
    "#         print('unaware')\n",
    "#         print(unaware_risk[risk])\n",
    "        aware_no_art_risk[:,risk] = np.apply_over_axes(np.sum, data_array[:,risk,:,aware_no_care_index], [0,2]).reshape(num_jur,)\n",
    "#         print('aware_no_art')\n",
    "#         print(aware_no_art_risk[risk])\n",
    "        aware_art_vls_risk[:,risk] = np.apply_over_axes(np.sum, data_array[:,risk,:,ART_VLS_index], [0,2]).reshape(num_jur,)\n",
    "#         print('art vls')\n",
    "#         print(aware_art_vls_risk[risk])\n",
    "\n",
    "        vls_risk[:,risk] = np.apply_over_axes(np.sum, data_array[:,risk,:,VLS_index], [0,2]).reshape(num_jur,)\n",
    "        \n",
    "    \n",
    "    total_pop = np.apply_over_axes(np.sum, data_array[:,:,:,0:21], [1,2,3]).reshape(num_jur,1)\n",
    "    \n",
    "    prevalence_prop = plwh_risk/total_pop\n",
    "    \n",
    "    unaware_prop = unaware_risk/plwh_risk\n",
    "    aware_no_art_prop = aware_no_art_risk/plwh_risk\n",
    "    aware_art_vls_prop = aware_art_vls_risk/plwh_risk\n",
    "    vls_prop = vls_risk/plwh_risk\n",
    "    \n",
    "    return total_pop, np.round(prevalence_prop, 6), np.round(unaware_prop, 6), \\\n",
    "                np.round(aware_no_art_prop, 6), np.round(aware_art_vls_prop, 6), vls_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ccd4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnosis_rate(data_array, num_jur, a_unaware, unaware_index, number_of_risk_groups, new_inf_per_month, unaware_prop, death_per_month_risk_age_compartments):\n",
    "    \n",
    "    diagnosis_rate_risk = np.zeros((num_jur, number_of_risk_groups))\n",
    "    \n",
    "    a_unaware_t = np.round(a_unaware*dt, 6)\n",
    "\n",
    "    for risk in range(len(risk_groups)):\n",
    "        # new infectiion per month\n",
    "        A = np.sum(new_inf_per_month, axis=2)[:,risk]\n",
    "\n",
    "        # number of unaware population\n",
    "        B = np.apply_over_axes(np.sum, data_array[:,risk,:,unaware_index], [0,2]).reshape(num_jur,)\n",
    "\n",
    "        #number of unaware next time period\n",
    "        # (current inf + new inf - total death)\n",
    "        C = (np.apply_over_axes(np.sum, data_array[:,risk,:,1:21], [1,2]).reshape(num_jur,) + A - np.apply_over_axes(np.sum, death_per_month_risk_age_compartments[:,risk,:,1:21],[1,2]).reshape(num_jur,)) * (unaware_prop[:,risk] + a_unaware_t[:,risk])\n",
    "\n",
    "        # total deaths in each compartment\n",
    "        D = np.apply_over_axes(np.sum, death_per_month_risk_age_compartments[:,risk,:,unaware_index],[0,2]).reshape(num_jur,)\n",
    "\n",
    "        # number of people in unaware compartment\n",
    "        E = np.sum(np.sum(data_array[:,risk,:, unaware_index],axis=2)*new_infections_data[\"testing_mult_fac_risk\"][risk].reshape(5,1), axis=0)\n",
    "        \n",
    "        diagnosis_rate_risk[:,risk] = (A+B-C-D)/E\n",
    "        \n",
    "        diagnosis_rate_risk[:,risk][diagnosis_rate_risk[:,risk] < 0] = 0\n",
    "        \n",
    "    return diagnosis_rate_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b8e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_rate(num_jur, a_art, ART_VLS_index, diagnosis_rate_risk, ltc_risk, gamma, number_of_risk_groups, data_array, new_inf_per_month, unaware_prop, aware_no_art_prop, aware_art_vls_prop, death_per_month_risk_age_compartments):\n",
    "    \n",
    "    dropout_rate_risk = np.zeros((num_jur, number_of_risk_groups))\n",
    "    \n",
    "    a_art_t = np.round(a_art *dt, 6)\n",
    "    gamma_t = np.round(gamma *dt, 6)\n",
    "    \n",
    "    for risk in range(len(risk_groups)):\n",
    "       # total art vls pop \n",
    "        F = np.apply_over_axes(np.sum, data_array[:,risk,:,ART_VLS_index], [0,2]).reshape(num_jur,)\n",
    "        #multiply F with phi for denominator\n",
    "        \n",
    "        K = np.sum(np.sum(data_array[:,risk,:,ART_VLS_index], axis=2)*scaling_factor_dropout[risk].reshape(10,1), axis=0)        \n",
    "        # diagnosed and linked to care\n",
    "        \n",
    "        G = diagnosis_rate_risk[:,risk]*ltc_risk[:,risk]*np.sum((np.sum(data_array[:,risk,:,unaware_index],axis=2))*new_infections_data[\"testing_mult_fac_risk\"][risk].reshape(5,1), axis=0)\n",
    "\n",
    "        #entering care from unaware\n",
    "        H = np.sum(gamma_t[risk].reshape(5,1)*np.sum(data_array[:,risk,:,aware_no_care_index], axis=2), axis=0)\n",
    "\n",
    "        #total death art vls\n",
    "        I = np.apply_over_axes(np.sum,death_per_month_risk_age_compartments[:,risk,:,ART_VLS_index],[0,2]).reshape(num_jur,)\n",
    "\n",
    "        #number of art vls next time period\n",
    "        J = (np.apply_over_axes(np.sum, data_array[:,risk,:,1:21], [1,2]).reshape(num_jur,) + np.sum(new_inf_per_month, axis=2)[:,risk] - np.apply_over_axes(np.sum, death_per_month_risk_age_compartments[:,risk,:,1:21],[1,2]).reshape(num_jur,)) * (aware_art_vls_prop[:,risk] + a_art_t[:,risk])\n",
    "        \n",
    "        dropout_rate_risk[:,risk] = (F+G+H-I-J)/K\n",
    "        \n",
    "#         if dropout_rate_risk[:,risk].any() < 0:\n",
    "        dropout_rate_risk[:,risk][dropout_rate_risk[:,risk] < 0] = 0\n",
    "        \n",
    "    return dropout_rate_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eda0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_matrix(num_jur, new_infections_data, diagnosis_rate_risk, dropout_rate_risk, ltc_risk):\n",
    "    \n",
    "    Q_MAT = new_infections_data['q']\n",
    "    Q_matrix = np.zeros((num_jur, number_of_risk_groups, number_of_compartments, number_of_compartments))\n",
    "    \n",
    "    for jur in range(num_jur):\n",
    "        for risk in range(number_of_risk_groups):\n",
    "            Q_mat = Q_MAT.copy()\n",
    "            Q_mat[np.where(Q_mat == 12345)] = (1 - ltc_risk[jur,risk]) * diagnosis_rate_risk[jur,risk]*new_infections_data[\"testing_mult_fac_risk\"][risk]\n",
    "            Q_mat[np.where(Q_mat == 123456)] = dropout_rate_risk[jur,risk]\n",
    "            Q_mat[np.where(Q_mat == 1234567)] = ltc_risk[jur,risk] * diagnosis_rate_risk[jur,risk]*new_infections_data[\"testing_mult_fac_risk\"][risk]\n",
    "\n",
    "            Q_matrix[jur,risk] = Q_mat\n",
    "            \n",
    "        \n",
    "    return Q_matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca4803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_mat_diag(Q_matrix, num_jur):\n",
    "    \n",
    "    Q_matrix_diagonal = np.zeros((num_jur, number_of_risk_groups, number_of_compartments, number_of_compartments))\n",
    "    \n",
    "    for jur in range(num_jur):\n",
    "        for risk in range(number_of_risk_groups):\n",
    "            Q_i = Q_matrix[jur,risk].copy()\n",
    "            Q_i_sum = np.sum(Q_i, 1)\n",
    "            Q_matrix_diagonal[jur,risk] = np.diag(Q_i_sum)\n",
    "        \n",
    "    return Q_matrix_diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd1dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop_susceptible_12_years = data_array_cluster[:,:,0,:]\n",
    "\n",
    "def aging(data_array, pop_susceptible_12_years):\n",
    "    new_pop = np.zeros((num_jur, number_of_risk_groups, num_age, number_of_compartments))\n",
    "    \n",
    "    new_pop[:,:,1:,:] = data_array[:,:,0:num_age-1,:]\n",
    "    new_pop[:,:,0,0] = pop_susceptible_12_years\n",
    "    \n",
    "    return new_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a6c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_state(data_array, prep_values):\n",
    "    \n",
    "    data_array_cluster1 = data_array[cluster1_index,:,:,:]\n",
    "    data_array_cluster2 = data_array[cluster2_index,:,:,:]\n",
    "    data_array_cluster3 = data_array[cluster3_index,:,:,:]\n",
    "    data_array_cluster4 = data_array[cluster4_index,:,:,:]\n",
    "    data_array_cluster5 = data_array[cluster5_index,:,:,:]\n",
    "    data_array_cluster6 = data_array[cluster6_index,:,:,:]\n",
    "    data_array_cluster7 = data_array[cluster7_index,:,:,:]\n",
    "    data_array_cluster8 = data_array[cluster8_index,:,:,:]\n",
    "    \n",
    "    #prep_rate\n",
    "    total_data_cluster1 = np.sum(data_array_cluster1, axis=0)\n",
    "    total_data_cluster1 = total_data_cluster1[np.newaxis,:,:,:]\n",
    "    \n",
    "    total_data_cluster2 = np.sum(data_array_cluster2, axis=0)\n",
    "    total_data_cluster2 = total_data_cluster2[np.newaxis,:,:,:]\n",
    "    \n",
    "    total_data_cluster3 = np.sum(data_array_cluster3, axis=0)\n",
    "    total_data_cluster3 = total_data_cluster3[np.newaxis,:,:,:]\n",
    "    \n",
    "    total_data_cluster4 = np.sum(data_array_cluster4, axis=0)\n",
    "    total_data_cluster4 = total_data_cluster4[np.newaxis,:,:,:]\n",
    "    \n",
    "    total_data_cluster5 = np.sum(data_array_cluster5, axis=0)\n",
    "    total_data_cluster5 = total_data_cluster5[np.newaxis,:,:,:]\n",
    "    \n",
    "    total_data_cluster6 = np.sum(data_array_cluster6, axis=0)\n",
    "    total_data_cluster6 = total_data_cluster6[np.newaxis,:,:,:]\n",
    "    \n",
    "    total_data_cluster7 = np.sum(data_array_cluster7, axis=0)\n",
    "    total_data_cluster7 = total_data_cluster7[np.newaxis,:,:,:]\n",
    "    \n",
    "    total_data_cluster8 = np.sum(data_array_cluster8, axis=0)\n",
    "    total_data_cluster8 = total_data_cluster8[np.newaxis,:,:,:]\n",
    "\n",
    "    \n",
    "    total_pop1, prevalence_prop1, unaware_prop1, aware_no_art_prop1, aware_art_vls_prop1,_ = calculate_proportions(total_data_cluster1, 1, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "    total_pop2, prevalence_prop2, unaware_prop2, aware_no_art_prop2, aware_art_vls_prop2,_ = calculate_proportions(total_data_cluster2, 1, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "    total_pop3, prevalence_prop3, unaware_prop3, aware_no_art_prop3, aware_art_vls_prop3,_ = calculate_proportions(total_data_cluster3, 1, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "    total_pop4, prevalence_prop4, unaware_prop4, aware_no_art_prop4, aware_art_vls_prop4,_ = calculate_proportions(total_data_cluster4, 1, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "    total_pop5, prevalence_prop5, unaware_prop5, aware_no_art_prop5, aware_art_vls_prop5,_ = calculate_proportions(total_data_cluster5, 1, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "    total_pop6, prevalence_prop6, unaware_prop6, aware_no_art_prop6, aware_art_vls_prop6,_ = calculate_proportions(total_data_cluster6, 1, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "    total_pop7, prevalence_prop7, unaware_prop7, aware_no_art_prop7, aware_art_vls_prop7,_ = calculate_proportions(total_data_cluster7, 1, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "    total_pop8, prevalence_prop8, unaware_prop8, aware_no_art_prop8, aware_art_vls_prop8,_ = calculate_proportions(total_data_cluster8, 1, number_of_risk_groups, unaware_index, aware_no_care_index, ART_VLS_index, VLS_index)\n",
    "\n",
    "    prep_coverage1 = data_array_cluster1[:,2,:,0]*prep_values[cluster1_index,2][:,np.newaxis]\n",
    "    prep1 = np.round(np.apply_over_axes(np.sum, prep_coverage1, [0,1]).item()/np.apply_over_axes(np.sum, data_array_cluster1[:,2,:,0], [0,1]).item(), 4)\n",
    "    prep_prop1 = np.array([0,0,prep1])\n",
    "    \n",
    "    prep_coverage2 = data_array_cluster2[:,2,:,0]*prep_values[cluster2_index,2][:,np.newaxis]\n",
    "    prep2 = np.round(np.apply_over_axes(np.sum, prep_coverage2,[0,1]).item()/np.apply_over_axes(np.sum, data_array_cluster2[:,2,:,0], [0,1]).item(), 4)\n",
    "    prep_prop2 = np.array([0,0,prep2])\n",
    "    \n",
    "    prep_coverage3= data_array_cluster3[:,2,:,0]*prep_values[cluster3_index,2][:,np.newaxis]\n",
    "    prep3= np.round(np.apply_over_axes(np.sum, prep_coverage3, [0,1]).item()/np.apply_over_axes(np.sum, data_array_cluster3[:,2,:,0], [0,1]).item(), 4)\n",
    "    prep_prop3= np.array([0,0,prep3])\n",
    "    \n",
    "    prep_coverage4 = data_array_cluster4[:,2,:,0]*prep_values[cluster4_index,2][:,np.newaxis]\n",
    "    prep4 = np.round(np.apply_over_axes(np.sum, prep_coverage4, [0,1]).item()/np.apply_over_axes(np.sum, data_array_cluster4[:,2,:,0], [0,1]).item(), 4)\n",
    "    prep_prop4 = np.array([0,0,prep4])\n",
    "    \n",
    "    prep_coverage5 = data_array_cluster5[:,2,:,0]*prep_values[cluster5_index,2][:,np.newaxis]\n",
    "    prep5 = np.round(np.apply_over_axes(np.sum, prep_coverage5,[0,1]).item()/np.apply_over_axes(np.sum, data_array_cluster5[:,2,:,0], [0,1]).item(), 4)\n",
    "    prep_prop5 = np.array([0,0,prep5])\n",
    "    \n",
    "    prep_coverage6 = data_array_cluster6[:,2,:,0]*prep_values[cluster6_index,2][:,np.newaxis]\n",
    "    prep6= np.round(np.apply_over_axes(np.sum, prep_coverage6, [0,1]).item()/np.apply_over_axes(np.sum, data_array_cluster6[:,2,:,0], [0,1]).item(), 4)\n",
    "    prep_prop6= np.array([0,0,prep6])\n",
    "    \n",
    "    prep_coverage7 = data_array_cluster7[:,2,:,0]*prep_values[cluster7_index,2][:,np.newaxis]\n",
    "    prep7 = np.round(np.apply_over_axes(np.sum, prep_coverage7, [0,1]).item()/np.apply_over_axes(np.sum, data_array_cluster7[:,2,:,0], [0,1]).item(), 4)\n",
    "    prep_prop7 = np.array([0,0,prep7])\n",
    "    \n",
    "    prep_coverage8 = data_array_cluster8[:,2,:,0]*prep_values[cluster8_index,2][:,np.newaxis]\n",
    "    prep8 = np.round(np.apply_over_axes(np.sum, prep_coverage8,[0,1]).item()/np.apply_over_axes(np.sum, data_array_cluster8[:,2,:,0], [0,1]).item(), 4)\n",
    "    prep_prop8 = np.array([0,0,prep8])\n",
    "    \n",
    "    \n",
    "    current_state1 = np.transpose(np.vstack((prevalence_prop1, unaware_prop1, aware_no_art_prop1, aware_art_vls_prop1, prep_prop1)))\n",
    "    current_state2 = np.transpose(np.vstack((prevalence_prop2, unaware_prop2, aware_no_art_prop2, aware_art_vls_prop2, prep_prop2)))\n",
    "    current_state3 = np.transpose(np.vstack((prevalence_prop3, unaware_prop3, aware_no_art_prop3, aware_art_vls_prop3, prep_prop3)))\n",
    "    current_state4 = np.transpose(np.vstack((prevalence_prop4, unaware_prop4, aware_no_art_prop4, aware_art_vls_prop4, prep_prop4)))\n",
    "    current_state5 = np.transpose(np.vstack((prevalence_prop5, unaware_prop5, aware_no_art_prop5, aware_art_vls_prop5, prep_prop5)))\n",
    "    current_state6 = np.transpose(np.vstack((prevalence_prop6, unaware_prop6, aware_no_art_prop6, aware_art_vls_prop6, prep_prop6)))\n",
    "    current_state7 = np.transpose(np.vstack((prevalence_prop7, unaware_prop7, aware_no_art_prop7, aware_art_vls_prop7, prep_prop7)))\n",
    "    current_state8 = np.transpose(np.vstack((prevalence_prop8, unaware_prop8, aware_no_art_prop8, aware_art_vls_prop8, prep_prop8)))\n",
    "    \n",
    "    return current_state1, current_state2, current_state3, current_state4, current_state5, current_state6, current_state7, current_state8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775b6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_data = data_array_cluster.copy()\n",
    "\n",
    "def initial_state(initial_data, prep_values):\n",
    "    state1,state2,state3,state4,state5,state6,state7,state8 = extract_state(initial_data, prep_values)\n",
    "    time = 0\n",
    "    return initial_data,state1,state2,state3,state4,state5,state6,state7,state8, prep_values, time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
